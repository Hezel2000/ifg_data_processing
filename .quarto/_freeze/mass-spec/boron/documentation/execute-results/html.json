{
  "hash": "c08405667006ac0404246090e20489b4",
  "result": {
    "markdown": "---\ntitle: Documentation\nauthor: Jie Xu & Dominik C. Hezel\ndate: 'January 25, 2023'\ntoc: true\nnumber-sections: true\nformat:\n  html:\n    code-fold: true\n---\n\n# Boron LA-ICP-MS Data Reduction Application\n\n## Introduction\nThis program is capable of:\n\n- Read multiple .exp data files\n- Read additional .csv files\n- Outlier rejection\n- Background correction\n- Intra-sequence Instrumental drift correction\n- Ablation volume dependent B concentration offset correction\n- Combination of calculation results, laser parameters and trace elements results\n- Ready to use final data table\n\n\n## How to use the Progame\n\n1. Upload data files from Neptune: click the 'Browse files' botton, then, use 'command A' to choose all '.exp' data files required from Neptune.\n\n2. Set up parameters for isotopic data: \n   (1). drag slider to choose bacground and signal area. Orange color zone represents background, and blue color zone is signal area.\n   (2). set your outlier factor: with smaller number, more data will be cut as outlier, which can be observed from red spots. \n   (3). set the bulge factor for 11B factor: this is related with bulge correction from 10B, 0.6 here as a factor is defined by Dr. Axel Gerdes.\n   (4). choose your standard for intra-sequence instrumental drift correction: the name, the 'A/B/C/D' inside the name of standard, the regression level.\n\n3. Upload your log file from laser: click the 'Browse files' botton and choose your laser file. (have a check if it is matched with isotopic data.)\n\n4. Set up parameters for corrected boron concentration from signal intensity:\n   (1). the regression level for boron concentration correction.\n   (2). insert the depth of selected reference depth and other sample depth if you have. Otherwise, just keep it.\n   (3). insert the shape of your spots: circle or squre.\n   (4). tell us if you used split stream or not.\n\n*5. Upload your trace element file if you used split stream. (not necessary) \n\n6. download your final results as a csv file.\n\n\n## Input File Requirements\n\n1. Input datafiles from Neptune:\n   (1). '.dat', '.exp', '.log', '.TDT' four type of datafiles for each measurement would be produced. Only '.exp' can be read successfully and can be openned by excel. \n   (2). underds datafiles are named in a format of 'num-A/B/C/D/U'(e.g. ‘001-A’,  ‘002-B’), num represents sequence number, A/B/C/D are four label for standards, U is label for unknown samples. Attention: all datafiles in one sequence need to be all uploaded once!\n   (3). Inside each '.exp' datafile, data start from the 23th row, and columns('9.9', '10B',\t'10.2', '11B') are necessary for data processing according to our method. \n\n2. Input laser file:\nthis is a csv file produced during abalation. Please have a check about all recorded information, which should be in the same order with Neptune datafile. Error may happen here.\n\n3. Input trace element datafile:\ntrace element data required from Ladr here. Raw data should be processed by Ladr and be appended here.\n\n\n## Description of the Python Code\n\nRequired packages\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport streamlit as st\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport statistics as stt\nfrom scipy import stats\nfrom scipy.optimize import curve_fit\n```\n:::\n\n\nUploading files, multiple files and only .exp files are allowed.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nif st.button('clear uploaded data'):\n    st.session_state.uploaded_files = []\n\nif 'uploaded_files' in st.session_state and len(st.session_state.uploaded_files) != 0:\n    uploaded_files = st.session_state.uploaded_files\n\nelse:\n    st.session_state.uploaded_files = st.file_uploader('upload files', type=['exp'], accept_multiple_files=True)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2023-03-25 07:57:36.480 \n  Warning: to view this Streamlit app on a browser, run it with the following\n  command:\n\n    streamlit run /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n2023-03-25 07:57:36.481 Session state does not function when running a script without `streamlit run`\n```\n:::\n:::\n\n\n### Explaining the Functions\n-> Include here explanations of what the functions do to the data, e.g., why the regression, why higher orders: or – why the subtraction of the backgrounds, what two backgrounds exist: the ‘normal’ one, and one from an unknown source\n\n\n**def selSmpType(dataFiles)**\n\nGet the sequence number for each datafile from their file name. The sequence number can be used for Instrumental drift correction later.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ndef selSmpType(dataFiles):\n    l = []\n    for file in dataFiles:    \n        l.append(float(file.split('_')[0]))\n    return l\n```\n:::\n\n\n**def outlierCorrection(data, factorSD)**\n\nOutlier rejection of data, data is out of factorSD times of standard deviation will be taken as outliers.\nThe first one is used for plot, the second one is used for calculation.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef outlierCorrection_plot(data, factorSD):\n    element_signal = np.array(data)\n    mean = np.mean(element_signal, axis=0)\n    sd = np.std(element_signal, axis=0)\n    fil = (data < mean + factorSD * sd) & (data > mean - factorSD * sd)\n    return fil\n\n\ndef outlierCorrection(data, factorSD):\n    element_signal = np.array(data)\n    mean = np.mean(element_signal, axis=0)\n    sd = np.std(element_signal, axis=0)\n\n    return [x for x in data if (x > mean - factorSD * sd) and (x < mean + factorSD * sd)]\n```\n:::\n\n\n**def parseBoronTable(file)**\n\nfind the useful data body from uploaded '.exp' datafiles. \n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef parseBoronTable(file):\n    #content = file.read()\n    content = file.getvalue().decode(\"utf-8\")\n    fname = file.__dict__[\"name\"]\n    _start = content.find(\"Cycle\\tTime\")\n    _end = content.find(\"***\\tCup\")\n    myTable = content[_start:_end-1]\n\n    cleanFname = f\"temp/{fname}_cleanTable\"\n    with open(cleanFname, \"w\") as _:\n        _.write(myTable)\n\n    df = pd.read_csv(cleanFname,\n                     sep='\\t',\n                     # dtype=\"float\"   #not working -->time\n                     )\n\n    return df, fname\n```\n:::\n\n\n**def sig_selection()**\n\nPlot the signal selection zone.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# st.session_state.sample_plot = st.selectbox(\n#     'Which is your sample to plot?',\n#     (st.session_state.uploaded_files))\n    \n# def sig_selection():\n#     average_B = []\n#     df_data, filename = parseBoronTable(st.session_state.sample_plot)\n#     df_data = df_data[['Cycle', '9.9', '10B', '10.2', '11B']].astype(float)\n\n#     fig, ax = plt.subplots()\n#     ax.plot(df_data['11B'], label='11B', c='green')\n#     ax.plot(df_data['10B'], label='10B', c='firebrick')\n#     ax.set_ylabel('signal intensity')\n#     ax.set_xlabel('cycle')\n#     x = df_data['11B'].index.to_numpy()\n#     ax.fill_between(x, max(df_data['11B']), where=(\n#         x < st.session_state.sig_end) & (x > st.session_state.sig_str), alpha=0.5)\n#     ax.fill_between(x, max(df_data['11B']), where=(\n#         x < st.session_state.bac_end) & (x > st.session_state.bac_str), alpha=0.5)\n\n#     ax.legend()\n#     return fig\n```\n:::\n\n\n**def bacground_sub(factorSD, factor_B11)**\n\nBackground subtraction. ‘9.9’, '10B', ’10.2’ and ‘11B’ are useful data here.\n(1). noise substraction from each cup.\n(2). bulge is defined by ‘9.9’ and ’10.2’. The average value of ‘9.9’ and ’10.2’ is applied for 10B correction, multiply 0.6 of the average value is applied for 11B correction.\n(3). the outlier data is plotted here.\n(4). the average of 11B/10B, standard deviation and name of datafile are returned.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef bacground_sub(factorSD, factor_B11):\n    average_B = []\n    for i in st.session_state.uploaded_files:\n        df_data, filename = parseBoronTable(i)\n        df_data = df_data[['Cycle', '9.9', '10B', '10.2', '11B']].astype(float)\n\n        df_bacground_mean = df_data[st.session_state.bac_str:st.session_state.bac_end].mean()\n        df_signal = df_data[st.session_state.sig_str:st.session_state.sig_end]\n\n        df_bacground_sub = df_signal - df_bacground_mean\n        df_bacground_sub['10B_bulc_sub'] = df_bacground_sub['10B'] - \\\n            (df_bacground_sub['9.9']+df_bacground_sub['10.2'])/2\n        df_bacground_sub['11B_bulc_sub'] = df_bacground_sub['11B'] - \\\n            factor_B11*(df_bacground_sub['9.9']+df_bacground_sub['10.2'])/2\n        df_bacground_sub['11B/10B'] = df_bacground_sub['11B_bulc_sub'] / \\\n            df_bacground_sub['10B_bulc_sub']\n        fil = outlierCorrection_plot(df_bacground_sub['11B/10B'], factorSD)\n        res_iso = df_bacground_sub['11B/10B'][fil]\n        res_iso_outlier = df_bacground_sub['11B/10B'][~fil]\n        res_11B = outlierCorrection(df_bacground_sub['11B'], factorSD)\n        if i == st.session_state.sample_plot:\n            fig1, ax = plt.subplots()\n            ax.plot(df_bacground_sub['11B/10B'], 'ko')\n            ax.plot(res_iso_outlier, 'ro', label='outliers')\n            ax.set_ylabel('$^{11}B$/$^{1O}B$')\n            ax.legend()\n            st.pyplot(fig1)\n        average_B.append({'filename': filename, '11B': np.mean(\n            res_11B), '11B/10B_row': np.mean(res_iso), 'se': np.std(res_iso)/np.sqrt(len(res_iso))})\n\n    df = pd.DataFrame(average_B)\n    st.session_state.average_B = df\n\n    return df\n```\n:::\n\n\n**def polynomFit(inp, \\*args)**\n\nused for regression function.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndef polynomFit(inp, *args):\n    x=inp\n    res=0\n    for order in range(len(args)):\n        res+=args[order] * x**order\n    return res\n```\n:::\n\n\n**def regression(x, y, ref_stand, order, listname)**\n\nGet the correction function of the Intra-sequence Instrumental drift.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef regression(x, y, ref_stand, order, listname):\n    x_use = np.array(x)\n    popt, pcov = curve_fit(polynomFit, xdata=x_use, ydata=y , p0=[0]*(order+1))\n    fitData=polynomFit(x_use,*popt)\n    \n    res = []\n    for unknown in listname:\n        y_unknown = ref_stand / polynomFit(unknown,*popt)\n        res.append({'factor': y_unknown})\n    return(pd.DataFrame(res))\n```\n:::\n\n\n**def regression_plot(x, y, ref_stand, order, listname)**\n\nReturn the plot the regress line.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndef regression_plot(x, y, ref_stand, order, listname):\n    fig, ax = plt.subplots()\n    ax.plot(x, y, label='measuered', marker='o', linestyle='none' )\n    x_use = np.array(x)\n    popt, pcov = curve_fit(polynomFit, xdata=x_use, ydata=y , p0=[0]*(order+1))\n    fitData=polynomFit(x_use,*popt)\n    ax.plot(x_use, fitData, label='polyn. fit, order '+str(order), linestyle='--' )\n    ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1))\n    \n    return fig\n```\n:::\n\n\n**def prepare_trace(datafile)**\n\nPrepare trace element datafile from Ladr: change the column titles and change data formate from str to float.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndef prepare_trace(datafile):\n    if 'LR' in datafile.columns[14]:\n        del datafile['44Ca(LR)']\n        del datafile['26Mg(LR)']\n    else:\n        del datafile['44Ca']\n        del datafile['26Mg']\n\n    datafile.columns = datafile.columns.str.replace('\\d+', '')\n    datafile.columns = datafile.columns.str.replace('\\('+'LR'+'\\)', '')\n    res = []\n    for i in range(13, len(datafile.columns)):\n        for j in datafile.iloc[:, i]:\n            if '<' in j:\n                res.append(j)\n    RES = datafile.replace(to_replace=res, value='nan', regex=True)\n    RES2 = RES.replace(\n        {'ERROR: Error (#1002): Internal standard composition can not be 0': np.nan})\n    RES3 = RES2.replace(\n        {'ERROR: Error (#1003): Calibration RM composition does not contain analyte element': np.nan})\n    RES4 = RES3.iloc[:, 13:].astype(float)\n    columns = RES4.iloc[:, 13:].columns\n    RES4[columns] = RES4.iloc[:, 13:]\n    RES4[' Sequence Number'] = RES3['LB#']\n    return(RES4)\n```\n:::\n\n\n**def processData()**\n\nUse functions for Intra-sequence Instrumental drift.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndef processData():\n    st.set_option('deprecation.showPyplotGlobalUse', False)\n    st.subheader('1.1 select your background and signal area')\n    st.session_state.bac_str, st.session_state.bac_end = st.slider('Select bacground', 0, 200, (5, 70))\n    st.session_state.sig_str, st.session_state.sig_end = st.slider('Select signal', 0, 200, (95, 175))\n    st.pyplot(sig_selection())\n\n    st.subheader('1.2 Please set your outlier and bulge factor')\n    outlier_factor = st.number_input('insert your outlier factor (means data is outlier_factor times of sd will be cut)',\n                                     value=1.5)\n    bulc_factor = st.number_input(\n        'insert your bulge factor for 11B correction', value=0.6)\n\n\n\n    if \"average_B\" in st.session_state:\n        df_data = st.session_state.average_B\n    else:\n        df_data = bacground_sub(outlier_factor, bulc_factor)\n\n    st.subheader(\n        '1.3 Please choose your standard for boron isotopes correction')\n\n    standard = st.selectbox(\n        'NIST 612 or B5 for correction?',\n        ('NIST SRM 612', 'B5'))\n    if standard == 'B5':\n        number_iso = int(4.0332057)\n        number_trace = int(8.42)\n        SRM951_value = int(4.0492)\n\n    if standard == 'NIST SRM 612':\n        number_iso = int(4.05015)\n        number_trace = int(35)\n        SRM951_value = int(4.0545)\n\n    st.session_state.standard_values = {\n        \"number_iso\" : number_iso,\n        \"number_trace\" : number_trace,\n        \"SRM951_value\" : SRM951_value\n\n    }\n\n    st.session_state.sample_correction = st.selectbox(\n        'Which type is your choosed standard?',\n        ('A', 'B', 'C', 'D'))\n\n    st.session_state.default_reg_level = 4\n    st.session_state.regress_level = st.number_input('insert your regression level (4 is recommended)', step=1, value=st.session_state.default_reg_level, format='%X'\n                                                     )\n    fil = df_data['filename'].str.contains(st.session_state.sample_correction)\n    df_data_B = df_data[fil]\n    df_data[' Sequence Number'] = selSmpType(df_data['filename'])\n\n    y_isotope = df_data_B['11B/10B_row']\n    y_11B = df_data_B['11B']\n    x = df_data_B.index.to_numpy()\n\n    factor_iso = regression(x, y_isotope,\n                            number_iso,\n                            st.session_state.regress_level if \"regress_level\" in st.session_state else st.session_state.default_reg_level,\n                            df_data.index.to_numpy()\n                            )\n\n    df_data['factor_iso'] = factor_iso\n\n    df_data['11B/10B_corrected'] = df_data['factor_iso']*df_data['11B/10B_row']\n    df_data['δ11B'] = ((df_data['11B/10B_corrected']/SRM951_value)-1)*1000\n    df_data['δ11B_se'] = (df_data['se']*df_data['factor_iso']/SRM951_value)*1000\n\n    st.session_state.df_data = df_data\n    st.session_state.df_data_B = df_data_B\n```\n:::\n\n\n**def processLaser()**\n\nUse functions and volume factors for corrected boron concerntrations.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ndef processLaser():\n    if \"df_data\" in st.session_state:\n        st.header('2. Please upload your log file from Laser')\n        st.session_state.uploaded_laser_file = st.file_uploader(\"Choose a laser file\", type='csv')\n        if st.session_state.uploaded_laser_file is not None:\n            st.session_state.df_Laser = pd.read_csv(st.session_state.uploaded_laser_file)\n\n            st.session_state.df_Laser_part1 = st.session_state.df_Laser[st.session_state.df_Laser[' Laser State']\n                                    == 'On'].iloc[:, [13, 20, 21]]\n            st.session_state.df_Laser_part2 = st.session_state.df_Laser[st.session_state.df_Laser[' Sequence Number'].notnull()].iloc[:, [\n                    1, 4]]\n\n            st.session_state.df_Laser_res = pd.concat([st.session_state.df_Laser_part2.reset_index(\n                    drop=True), st.session_state.df_Laser_part1.reset_index(drop=True)], axis=1)\n                    \n            st.session_state.df_map1 = st.session_state.df_Laser_res.merge(st.session_state.df_data, on=' Sequence Number')\n\n            st.subheader('2.1 B concerntration correction')\n            st.session_state.regress_level_B = st.number_input('insert your regression level for [B] (4 is recommended)', \n            step=1, \n            value=st.session_state.default_reg_level, \n            format='%X'\n                                                            )     \n\n            y_isotope = st.session_state.df_data_B['11B/10B_row']\n            y_11B = st.session_state.df_data_B['11B']\n            x = st.session_state.df_data_B.index.to_numpy()   \n            factor_B = regression(x, y_11B, st.session_state.standard_values[\"number_trace\"],\n                            st.session_state.regress_level_B if \"regress_level_B\" in st.session_state else st.session_state.default_reg_level_B, \n                            st.session_state.df_data.index.to_numpy()\n                            )\n            st.session_state.df_map1['factor_B'] = factor_B\n            \n\n            depth_ref = st.number_input('insert the abalation depth of selected reference / µm', value = 30.0)\n            depth_sample = st.number_input('insert the abalation depth of other samples / µm', value = 30.0)\n                    \n            depth_ratios = []\n            for i in st.session_state.df_map1['filename'].str.contains('A'):\n                if i == True:\n                    depth_ratio = 1 \n                else:\n                    depth_ratio = depth_sample / depth_ref\n                depth_ratios.append(depth_ratio)\n\n            st.session_state.df_map1['depth_correction'] = depth_ratios\n\n            spot_shape = st.selectbox(\n                        'What is the type of your spots?',\n                        ('circle', 'squre'))\n            if spot_shape == 'circle':\n                st.session_state.df_map1[' Spot Size (um)'] = st.session_state.df_Laser_res[' Spot Size (um)']\n                ref = ((st.session_state.df_map1[st.session_state.df_map1['filename'].str.contains(st.session_state.sample_correction)][' Spot Size (um)']/2)**2).mean()\n                st.session_state.df_map1['[B]_corrected'] = st.session_state.df_map1['11B']*st.session_state.df_map1['factor_B'] * (ref / ((st.session_state.df_map1[' Spot Size (um)']/2)**2) / depth_ratios)\n\n            if spot_shape == 'squre':\n\n                dia = st.session_state.df_map1[' Spot Size (um)']\n                spotsize = dia.str.split(' ').str[0].apply(lambda x: float(x))\n                st.session_state.df_map1[' Spot Size (um)'] = spotsize\n                ref = ((st.session_state.df_map1[st.session_state.df_map1['filename'].str.contains(st.session_state.sample_correction)][' Spot Size (um)'])**2).mean()\n                st.session_state.df_map1['[B]_corrected'] = st.session_state.df_map1['11B']*st.session_state.df_map1['factor_B'] * (ref / ((st.session_state.df_map1[' Spot Size (um)'])**2) / depth_ratios)   \n    \n            st.session_state.df_map1 = st.session_state.df_map1\n\n```\n:::\n\n\n**def maping()**\n\nupload trace element datafile and merge laser parameter, isotopic results and trace element compositions into one file based on sequence number.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ndef maping():\n    if \"df_map1\" in st.session_state:\n        st.subheader('2.2 export results or append your trace elements')\n\n        trace_file = st.selectbox(\n            'split stream or not?',\n            ('Split stream', 'No'))\n\n        if trace_file == 'No':\n            st.session_state.df_all = st.session_state.df_map1\n\n\n        elif trace_file == 'Split stream':\n            st.header('3. Please upload your trace element data processed from Ladr')\n\n            st.session_state.trace = st.file_uploader(\"Choose a file\", type='csv', accept_multiple_files=True)\n            if \"trace\" in  st.session_state and len(st.session_state.trace) > 0:\n\n                trace_file = pd.read_csv(st.session_state.trace[0])\n\n                #trace_file = pd.read_csv('2022-11-28-Si corrected-B5.csv')\n\n                df_trace = prepare_trace(trace_file)\n\n                st.session_state.df_all = st.session_state.df_map1.merge(df_trace, on=' Sequence Number')\n                # fig4, ax = plt.subplots()\n                # ax.plot([0,1],[0,1], transform=ax.transAxes, c = 'red')\n                # ax.scatter(st.session_state.df_all['[B]_corrected'], st.session_state.df_all['B'], s =70, c = 'darkorange', edgecolors = 'black')\n                # ax.set_ylabel('[B]_measured by Element')\n                # ax.set_xlabel('[B]_corrected by Neptune')\n                # st.pyplot(fig4)\n\n\n        if \"df_all\" in st.session_state:\n            st.session_state.df_all.to_csv('final.csv')\n            st.write(st.session_state.df_all)\n            result_csv = st.session_state.df_all.to_csv().encode('utf-8')\n            st.download_button(\n                label='download results as .csv',\n                data=result_csv,\n                file_name='boron results.csv',\n                mime='txt/csv',\n            )\n\n```\n:::\n\n\n###\tExplaining the Main Body of the Code\nrun thw function: \n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# if len(st.session_state.uploaded_files) != 0:\n#     processData()\n\n# processLaser()\n# maping()\n\n```\n:::\n\n\n## Explain the Output\n\nWhat exactly is the output, likely best with screen shots.\n \n-->’Sequence Number’ column: the number of datafile in all sequence.\n-->The ‘Comment’ column: sample name, labelled by yourself during measuring.\n--> ‘Spot size (um)’, ‘Laser HV (kV)’, ‘Laser Energy (mJ)’: useful information selected from laser parameters.\n-->The ‘filename’ column: name of datafile.\n-->from ‘11B’ to ‘factor_iso’: all results from Neptune. ‘[B]_corrected’ is calculated B concentrations from 11B. ‘δ11B’ and ‘δ11B_se’column are calculated isotope results and erros.\n-->from ‘Li’, ‘B’ to ‘U’ are all trace element results from Element XR.\n\n(the following is copied from what was a ‘text’ file.)\n1. csv files are changed from original .exp file\n2. data automatically from machine can be found in 'data/original data type'.\n\n\n## Testing\n\nFor a demonstration of a line plot on a polar axis, see @fig-polar.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![A line plot on a polar axis](documentation_files/figure-html/fig-polar-output-1.png){#fig-polar width=450 height=439}\n:::\n:::\n\n\n",
    "supporting": [
      "documentation_files"
    ],
    "filters": [],
    "includes": {}
  }
}